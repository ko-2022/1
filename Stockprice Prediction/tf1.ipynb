{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Date       400 non-null    object\n",
      " 1   Open       400 non-null    object\n",
      " 2   High       400 non-null    object\n",
      " 3   Low        400 non-null    object\n",
      " 4   Close      400 non-null    object\n",
      " 5   Adj Close  400 non-null    object\n",
      " 6   Volume     400 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 22.0+ KB\n",
      "stock_info.shape:  (399, 6)\n",
      "stock_info[0]:  [6.1220001e+01 6.3026001e+01 5.9759998e+01 6.2023998e+01 6.2023998e+01\n",
      " 5.8293000e+07]\n",
      "price.shape:  (399, 5)\n",
      "price[0]:  [61.220001 63.026001 59.759998 62.023998 62.023998]\n",
      "norm_price[0]:  [0.07979605 0.08537702 0.0752843  0.08228059 0.08228059]\n",
      "====================================================================================================\n",
      "volume.shape:  (399, 1)\n",
      "volume[0]:  [58293000.]\n",
      "norm_volume[0]:  [0.15721732]\n",
      "====================================================================================================\n",
      "x.shape:  (399, 6)\n",
      "x[0]:  [0.07979605 0.08537702 0.0752843  0.08228059 0.08228059 0.15721732]\n",
      "x[-1]:  [0.82695306 0.82822007 0.76884433 0.77488881 0.77488881 0.1666165 ]\n",
      "====================================================================================================\n",
      "y[0]:  [0.08228059]\n",
      "y[-1]:  [0.77488881]\n",
      "[[0.07979605 0.08537702 0.0752843  0.08228059 0.08228059 0.15721732]\n",
      " [0.0803523  0.08183561 0.07440669 0.07624846 0.07624846 0.07695149]\n",
      " [0.07973425 0.0871508  0.07771324 0.08695921 0.08695921 0.08428648]] -> [0.09763288]\n",
      "X:  Tensor(\"Placeholder:0\", shape=(?, 3, 6), dtype=float32)\n",
      "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
      "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-1-5737b6e4c503>:134: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:753: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 3, 20), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v1' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5737b6e4c503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_column_cnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v1' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "def data_standardization(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.mean()) / x_np.std()\n",
    "\n",
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7)\n",
    "\n",
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()\n",
    " \n",
    " \n",
    "\n",
    "input_data_column_cnt = 6\n",
    "output_data_column_cnt = 1\n",
    " \n",
    "seq_length = 3\n",
    "rnn_cell_hidden_dim = 20\n",
    "forget_bias = 1.0\n",
    "num_stacked_layers = 1\n",
    "keep_prob = 0.8\n",
    " \n",
    "epoch_num = 1000\n",
    "learning_rate = 0.01\n",
    " \n",
    "\n",
    "stock_file_name = 'TSLA.csv'\n",
    "encoding = 'utf-8'\n",
    "names = ['Date','Open','High','Low','Close','Adj Close','Volume']\n",
    "raw_dataframe = pd.read_csv(stock_file_name, names=names, encoding=encoding)\n",
    "raw_dataframe.info()\n",
    " \n",
    "\n",
    "del raw_dataframe['Date']\n",
    " \n",
    "stock_info = raw_dataframe.values[1:].astype(np.float)\n",
    "print(\"stock_info.shape: \", stock_info.shape)\n",
    "print(\"stock_info[0]: \", stock_info[0])\n",
    " \n",
    "\n",
    "price = stock_info[:,:-1]\n",
    "norm_price = min_max_scaling(price)\n",
    "print(\"price.shape: \", price.shape)\n",
    "print(\"price[0]: \", price[0])\n",
    "print(\"norm_price[0]: \", norm_price[0])\n",
    "print(\"=\"*100)\n",
    "\n",
    "volume = stock_info[:,-1:]\n",
    "norm_volume = min_max_scaling(volume)\n",
    "print(\"volume.shape: \", volume.shape)\n",
    "print(\"volume[0]: \", volume[0])\n",
    "print(\"norm_volume[0]: \", norm_volume[0])\n",
    "print(\"=\"*100)\n",
    " \n",
    "x = np.concatenate((norm_price, norm_volume), axis=1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "print(\"x[0]: \", x[0])\n",
    "print(\"x[-1]: \", x[-1])\n",
    "print(\"=\"*100)\n",
    " \n",
    "y = x[:, [-2]]\n",
    "print(\"y[0]: \",y[0])\n",
    "print(\"y[-1]: \",y[-1])\n",
    " \n",
    " \n",
    "dataX = []\n",
    "dataY = []\n",
    " \n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i : i+seq_length]\n",
    "    _y = y[i + seq_length]\n",
    "    if i is 0:\n",
    "        print(_x, \"->\", _y)\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)\n",
    " \n",
    " \n",
    "train_size = int(len(dataY) * 0.7)\n",
    "\n",
    "test_size = len(dataY) - train_size\n",
    " \n",
    "\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    " \n",
    "\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])\n",
    " \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
    "print(\"X: \", X)\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"Y: \", Y)\n",
    " \n",
    "\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"targets: \", targets)\n",
    " \n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"predictions: \", predictions)\n",
    " \n",
    " \n",
    "\n",
    "def lstm_cell():\n",
    "\n",
    "    # num_units\n",
    "    # forget_bias:  to the biases of the forget gate \n",
    "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
    "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
    "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
    "    cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n",
    " \n",
    "\n",
    "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.compat.v1.nn.rnn_cell.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
    " \n",
    "\n",
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "print(\"hypothesis: \", hypothesis)\n",
    " \n",
    "\n",
    "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
    " \n",
    " \n",
    "\n",
    "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    " \n",
    "train = optimizer.minimize(loss)\n",
    " \n",
    "\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    " \n",
    " \n",
    "train_error_summary = []\n",
    "test_error_summary = []\n",
    "test_predict = ''\n",
    " \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print('Start learning...')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch+1) % 100 == 0) or (epoch == epoch_num-1):\n",
    "\n",
    "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
    "        train_error_summary.append(train_error)\n",
    " \n",
    "\n",
    "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
    "        test_error_summary.append(test_error)\n",
    "        \n",
    "\n",
    "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
    "        \n",
    "end_time = datetime.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elapsed_time:',elapsed_time)\n",
    "print('elapsed_time per epoch:',elapsed_time/epoch_num)\n",
    " \n",
    "\n",
    "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
    "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
    " \n",
    "print(',seq_length:', seq_length, end='')\n",
    "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
    "print(',forget_bias:', forget_bias, end='')\n",
    "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
    "print(',keep_prob:', keep_prob, end='')\n",
    " \n",
    "print(',epoch_num:', epoch_num, end='')\n",
    "print(',learning_rate:', learning_rate, end='')\n",
    " \n",
    "print(',train_error:', train_error_summary[-1], end='')\n",
    "print(',test_error:', test_error_summary[-1], end='')\n",
    "print(',min_test_error:', np.min(test_error_summary))\n",
    " \n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(train_error_summary, 'gold')\n",
    "plt.plot(test_error_summary, 'b')\n",
    "plt.xlabel('Epoch(x100)')\n",
    "plt.ylabel('Root Mean Square Error')\n",
    " \n",
    "plt.figure(2)\n",
    "plt.plot(testY, 'r')\n",
    "plt.plot(test_predict, 'b')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "\n",
    "recent_data = np.array([x[len(x)-seq_length : ]])\n",
    "print(\"recent_data.shape:\", recent_data.shape)\n",
    "print(\"recent_data:\", recent_data)\n",
    " \n",
    "\n",
    "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
    " \n",
    "print(\"test_predict\", test_predict[0])\n",
    "test_predict = reverse_min_max_scaling(price,test_predict)\n",
    "print(\"Tomorrow's stock price\", test_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.12.1-cp36-cp36m-manylinux2010_x86_64.whl (703 kB)\n",
      "\u001b[K     |████████████████████████████████| 703 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.11.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.12.1 typeguard-2.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting finance-datareader\n",
      "  Downloading finance_datareader-0.9.31-py3-none-any.whl (17 kB)\n",
      "Collecting requests-file\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (2.25.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.6.3-cp36-cp36m-manylinux1_x86_64.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from finance-datareader) (1.1.5)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19.2->finance-datareader) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.3.0->finance-datareader) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->finance-datareader) (4.0.0)\n",
      "Installing collected packages: tqdm, requests-file, lxml, finance-datareader\n",
      "Successfully installed finance-datareader-0.9.31 lxml-4.6.3 requests-file-1.5.1 tqdm-4.59.0\n"
     ]
    }
   ],
   "source": [
    "!pip install finance-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
